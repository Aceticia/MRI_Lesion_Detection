{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "demographic-grill",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "73f5e2d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import matplotlib\n",
    "import torch.nn as nn\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52aaecbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "86bbb3ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def positive_pair(data):\n",
    "    [batch_size,q,h,w]=data.shape\n",
    "    ret=np.array(data)\n",
    "    NOISE_R=0.7\n",
    "    FLIP_R=0.6\n",
    "    r1=random.random()\n",
    "    #add random noise\n",
    "    if r1<NOISE_R:\n",
    "        ret=ret+np.random.randn(batch_size,q,h,w)*12\n",
    "    #flip image randomly on all dimensions\n",
    "    r2=random.random()\n",
    "    if r2<FLIP_R:\n",
    "        ret=ret[:,::-1,:,:]\n",
    "    r3=random.random()\n",
    "    if r3<FLIP_R:\n",
    "        ret=ret[:,:,::-1,:]\n",
    "    if random.random()<0.6 or (r1>NOISE_R and r2>FLIP_R and r1>FLIP_R):\n",
    "        ret=ret[:,:,:,::-1]\n",
    "    return torch.as_tensor(ret.copy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "41798c7e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not used\n",
    "def data_padding(data):\n",
    "    [batch_size,nx,ny,nz]=data.shape\n",
    "    maxr=max(nx,ny,nz)\n",
    "    data2=np.zeros([batch_size,maxr,maxr,maxr])\n",
    "    for i in range(batch_size):\n",
    "        for x in range(nx):\n",
    "            for y in range(ny):\n",
    "                for z in range(nz):\n",
    "                    data2[i,x+(maxr-nx)//2,y+(maxr-ny)//2,z+(maxr-nz)//2]=data[i,x,y,z]\n",
    "    return data2.copy()\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7bc41c0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Different shape on different slices\n",
    "class cnn_multi_dim(nn.Module):\n",
    "    def __init__(self,dim=0,output_dim=10):\n",
    "        super(cnn_multi_dim,self).__init__()\n",
    "        if dim==1:\n",
    "            self.conv=nn.Sequential(\n",
    "                nn.Conv2d(1,8,5,1,0),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(8,32,3,1,0),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(32,32,3,1,0),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "            )\n",
    "            self.out=nn.Linear(2592,output_dim)\n",
    "        else:\n",
    "            self.conv=nn.Sequential(\n",
    "                nn.Conv2d(1,8,5,1,0),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(8,32,3,1,0),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "                nn.Conv2d(32,32,3,1,0),\n",
    "                nn.ReLU(),\n",
    "                nn.MaxPool2d(2),\n",
    "            )\n",
    "            self.out=nn.Linear(3168,output_dim)    \n",
    "        self.output_dim=output_dim\n",
    "            \n",
    "    def forward(self,x):\n",
    "            y=x.view([x.shape[1]*x.shape[0],1,x.shape[2],x.shape[3]])\n",
    "            y=self.conv(y)\n",
    "            y=y.view(y.size(0),-1)\n",
    "            y=self.out(y)\n",
    "            y=y.view(1,y.shape[0],y.shape[1])\n",
    "            y=nn.AvgPool2d(kernel_size=[x.shape[1],1],stride=[x.shape[1],1])(y)\n",
    "            y=y.view(y.shape[1],y.shape[2])\n",
    "            return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f7548de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(loader,ep,lrate,alpha):\n",
    "    cnn=[cnn_multi_dim(0),cnn_multi_dim(1),cnn_multi_dim(2)]\n",
    "    optimizer=torch.optim.Adam([{\"params\":cnn[0].parameters()},{\"params\":cnn[1].parameters()},{\"params\":cnn[2].parameters()}],lrate)\n",
    "    for epoch in range(ep):\n",
    "        losses=[]\n",
    "        for _,d in enumerate(loader):\n",
    "            if (_>0):\n",
    "                positive=positive_pair(d)\n",
    "                # Generate slices\n",
    "                tran_d=[d,d.permute(0,2,1,3),d.permute(0,3,1,2)]\n",
    "                tran_neg=[negative,negative.permute(0,2,1,3),negative.permute(0,3,1,2)]\n",
    "                tran_pos=[positive,positive.permute(0,2,1,3),positive.permute(0,3,1,2)]\n",
    "                pred_d=[_,_,_]\n",
    "                pred_pos=[_,_,_]\n",
    "                pred_neg=[_,_,_]\n",
    "                loss=0\n",
    "                for dim in range(3):\n",
    "                    pred_d[dim]=cnn[dim](tran_d[dim].float())\n",
    "                    pred_pos[dim]=cnn[dim](tran_pos[dim].float())\n",
    "                    pred_neg[dim]=cnn[dim](tran_neg[dim].float())\n",
    "                    d1=pred_d[dim]-pred_pos[dim]\n",
    "                    d2=pred_d[dim]-pred_neg[dim]\n",
    "                    d1=torch.norm(d1)\n",
    "                    d2=torch.norm(d2)\n",
    "                    loss=loss+nn.ReLU()(d1-d2+alpha)\n",
    "\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "                #print(epoch,_,loss.item())\n",
    "                losses.append(loss.item())\n",
    "            negative=d\n",
    "        print('epoch:',epoch,'loss:',np.array(losses).mean())\n",
    "        state={0:cnn[0].state_dict(),1:cnn[1].state_dict(),2:cnn[0].state_dict()}\n",
    "        torch.save(state,'checkpointat{}.pth'.format(epoch))\n",
    "    return cnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c3e52a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "def output(nets,images):\n",
    "    ret=np.zeros((images.shape[0],3,nets[0].output_dim))\n",
    "    loader=torch.utils.data.DataLoader(dataset=images,batch_size=images.shape[0],shuffle=False)\n",
    "    with torch.no_grad():\n",
    "        for _,d in enumerate(loader):\n",
    "            # Generate slices\n",
    "            tran_d=[d,d.permute(0,2,1,3),d.permute(0,3,1,2)]\n",
    "            pred_d=[_,_,_]\n",
    "            for dim in range(3):\n",
    "                nets[dim].eval()\n",
    "                pred_d[dim]=nets[dim](tran_d[dim].float())\n",
    "                ret[:,dim,:]=pred_d[dim].numpy()\n",
    "    return ret\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5af30b79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 29.903202692667644\n",
      "epoch: 1 loss: 28.640853881835938\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[cnn_multi_dim(\n",
       "   (conv): Sequential(\n",
       "     (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU()\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (3): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (4): ReLU()\n",
       "     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (7): ReLU()\n",
       "     (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (out): Linear(in_features=3168, out_features=10, bias=True)\n",
       " ),\n",
       " cnn_multi_dim(\n",
       "   (conv): Sequential(\n",
       "     (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU()\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (3): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (4): ReLU()\n",
       "     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (7): ReLU()\n",
       "     (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (out): Linear(in_features=2592, out_features=10, bias=True)\n",
       " ),\n",
       " cnn_multi_dim(\n",
       "   (conv): Sequential(\n",
       "     (0): Conv2d(1, 8, kernel_size=(5, 5), stride=(1, 1))\n",
       "     (1): ReLU()\n",
       "     (2): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (3): Conv2d(8, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (4): ReLU()\n",
       "     (5): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "     (6): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1))\n",
       "     (7): ReLU()\n",
       "     (8): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
       "   )\n",
       "   (out): Linear(in_features=3168, out_features=10, bias=True)\n",
       " )]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#182 218 182\n",
    "data=np.random.rand(12,91,109,91)*200\n",
    "batch_size=3\n",
    "dataloader=torch.utils.data.DataLoader(dataset=data,batch_size=batch_size,shuffle=True)\n",
    "train(dataloader,2,1e-3,10)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d2b1f1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nibabel as nib\n",
    "#img=nib.load('MPRFlirt_0.nii.gz')\n",
    "#imgdata=np.array(img.get_fdata())\n",
    "#print(imgdata.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f3e484da",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MeanPool3d(img,kernel):\n",
    "    s=img.shape\n",
    "    ret=np.zeros((s[0]//kernel,s[1]//kernel,s[2]//kernel))\n",
    "    for i in range(0,s[0],kernel):\n",
    "        for j in range(0,s[1],kernel):\n",
    "            for k in range(0,s[2],kernel):\n",
    "                r=img[i:i+kernel,j:j+kernel,k:k+kernel]\n",
    "                avg=r.mean()\n",
    "                ret[i//kernel,j//kernel,k//kernel]=avg\n",
    "    return ret            \n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "252b2f34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "................................(32, 91, 109, 91)\n"
     ]
    }
   ],
   "source": [
    "ndata=32\n",
    "data=[]\n",
    "for i in range(ndata):\n",
    "    img=nib.load('MPRFlirt_{}.nii.gz'.format(i))\n",
    "    imgdata=np.array(img.get_fdata())\n",
    "    imgdata=MeanPool3d(imgdata,2)\n",
    "    data.append(imgdata)\n",
    "    print('.',end='')\n",
    "data=np.array(data)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b36dff2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size=2\n",
    "dataloader=torch.utils.data.DataLoader(dataset=data,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2b3af544",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch: 0 loss: 108.20485763549804\n",
      "epoch: 1 loss: 80.13615417480469\n",
      "epoch: 2 loss: 67.57412618001302\n",
      "epoch: 3 loss: 48.27934010823568\n",
      "epoch: 4 loss: 37.01170260111491\n",
      "epoch: 5 loss: 23.869907506306966\n",
      "epoch: 6 loss: 18.490877405802408\n",
      "epoch: 7 loss: 15.882590993245442\n",
      "epoch: 8 loss: 12.98216183980306\n",
      "epoch: 9 loss: 7.426420084635416\n"
     ]
    }
   ],
   "source": [
    "cnns=train(dataloader,10,1e-5,40)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "dc95e74b",
   "metadata": {},
   "outputs": [],
   "source": [
    "features=output(cnns,data[0:4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8186d7dd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "83cbddc4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[[-18.04083443 -30.10380173   9.25126839 -24.64769363  19.53997231\n",
      "   -23.32155609  12.49834633 -22.53586769 -19.83687019 -27.53133774]\n",
      "  [ 14.11794281   9.75600624 -13.1545105   18.08741379  17.60120773\n",
      "    18.08508301  17.818573    12.37252617 -12.44902802  13.12752151]\n",
      "  [  9.53529358   7.29224586   6.42493439  -7.90307045  -6.19275856\n",
      "    -7.53355789  -4.94872665   6.91421318   6.90393257   8.67295074]]\n",
      "\n",
      " [[-13.49768257 -24.45940781  10.14556313 -19.16000748  14.18871498\n",
      "   -19.68483734   8.31364632 -17.77193642 -14.22083473 -21.8798027 ]\n",
      "  [ 20.84435272  13.15213203 -21.20957947  22.71351242  23.44721603\n",
      "    22.60429382  22.89402771  15.6972332  -22.35839081  20.63333511]\n",
      "  [ 11.5473938   11.02936745  14.00681305 -10.71984291 -11.41077614\n",
      "   -13.0578804   -9.56788254  11.11262321  10.13861275  11.70465851]]\n",
      "\n",
      " [[ 18.55711174  30.03129959 -11.36250877  25.46561813 -20.0010891\n",
      "    24.33745575 -12.10825157  23.25816154  18.68953514  27.5301857 ]\n",
      "  [-16.34326935 -10.33164024  15.41595459 -19.38187027 -20.31387711\n",
      "   -18.70477295 -20.62234497 -13.94980812  14.71793365 -13.28794479]\n",
      "  [ -9.77676392  -7.45946312  -8.22245026   7.99464989   7.03958702\n",
      "     7.95977402   5.30656052  -7.24270058  -7.2421627   -8.59148407]]\n",
      "\n",
      " [[ 12.98140526  24.53190994  -8.03432274  18.34208298 -13.72759819\n",
      "    18.66893768  -8.70374107  17.04964256  15.36816978  21.88095474]\n",
      "  [-18.61902618 -12.57649803  18.94813538 -21.41905594 -20.73454666\n",
      "   -21.98460388 -20.09025574 -14.11995125  20.08948517 -20.47291183]\n",
      "  [-11.30592346 -10.86215019 -12.20929718  10.62826347  10.56394768\n",
      "    12.63166428   9.21004868 -10.78413582  -9.80038261 -11.78612518]]]\n"
     ]
    }
   ],
   "source": [
    "print(features-np.mean(features,axis=0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1354f92c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
