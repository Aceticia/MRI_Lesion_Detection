{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "995bec26",
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import sys\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import glob\n",
    "import pickle\n",
    "from tqdm import tqdm\n",
    "import nibabel as nib\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "2b159dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch import optim\n",
    "from torchvision import transforms\n",
    "\n",
    "from torch.utils.data import Dataset, TensorDataset, random_split, SubsetRandomSampler, ConcatDataset\n",
    "from sklearn.model_selection import KFold\n",
    "\n",
    "from skimage.transform import resize \n",
    "\n",
    "from sklearn.metrics import mean_absolute_error as mae\n",
    "from torch.autograd import Variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "9ac1a1a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use the GPU if you have one\n",
    "device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "id": "2a7ef7e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#single scale\n",
    "class fc_layer(nn.Module):\n",
    "    def __init__(self, in_layer, out_layer):\n",
    "        super(fc_layer, self).__init__()\n",
    "        self.fc = nn.Linear(in_layer, out_layer)\n",
    "        #if in_features=5 and out_features=10 and the input tensor x \n",
    "        #has dimensions 2-3-5, then the output tensor will have dimensions 2-3-10???\n",
    "        #\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.fc(x)\n",
    "\n",
    "class avg_pool(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(avg_pool, self).__init__()\n",
    "        self.avgp = nn.AvgPool3d(2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        return self.avgp(x)\n",
    "\n",
    "class softmax_layer(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(softmax_layer, self).__init__()\n",
    "        self.softmax = nn.Softmax(dim=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.softmax(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "ad8eac38",
   "metadata": {},
   "outputs": [],
   "source": [
    "def customToTensor(img):\n",
    "    if isinstance(img, np.ndarray):\n",
    "        img1 = torch.from_numpy(img)\n",
    "        img1 = resize_image(img, (150, 150, 200))\n",
    "        # backward compatibility\n",
    "        return img1.astype(np.float32)\n",
    "\n",
    "def resize_image(img_array, trg_size):\n",
    "    res = resize(img_array, trg_size, mode='reflect', preserve_range=True, anti_aliasing=False)\n",
    "    # type check\n",
    "    if type(res) != np.ndarray:\n",
    "        raise \"type error!\"\n",
    "    return res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "23998249",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_EPOCH = 50\n",
    "BATCH_SIZE = 20\n",
    "LR = 0.001\n",
    "SAVE_PATH_AP = r'C:\\Users\\pbhav\\Desktop\\NYU\\ivp\\project\\model\\AP' #path to save age prediction model\n",
    "SAVE_PATH_BC = r'C:\\Users\\pbhav\\Desktop\\NYU\\ivp\\project\\model\\BC' #path to save disease classification madel"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "id": "9b7dfb96",
   "metadata": {},
   "outputs": [],
   "source": [
    "#data prep\n",
    "class ADNI_Dataset_classification(Dataset):\n",
    "    def __init__(self, root_dir, data_file):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            root_dir (string): Directory of all the images.\n",
    "            data_file (string): File name of the train/test split file.\n",
    "        \"\"\"\n",
    "        self.root_dir = root_dir\n",
    "        self.data_file = data_file\n",
    "    \n",
    "    def __len__(self):\n",
    "        return sum(1 for line in open(self.data_file))\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        df = open(self.data_file)\n",
    "        lines = df.readlines()\n",
    "        lst = lines[idx].split(',')\n",
    "        img_name = lst[0].strip('\\\"')\n",
    "        img_label = lst[2].strip('\\\"')\n",
    "        image_path = os.path.join(self.root_dir, img_name) + '.nii'\n",
    "        image = nib.load(image_path)\n",
    "        a = (image.get_fdata()) #convert to np array\n",
    "        a = customToTensor(a)\n",
    "        \n",
    "        if img_label == 'CN': #Cognitive Normal\n",
    "            label = 0\n",
    "        elif img_label == 'AD': #Alzheimer's \n",
    "            label = 1\n",
    "        elif img_label == 'MCI': #Mild Cognitive Impairement\n",
    "            label = 2\n",
    "\n",
    "        sample = {'image': a, 'label': label}\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "b527f77f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#loss function for classification\n",
    "def a_value(y_true, y_pred_prob, zero_label=0, one_label=1):\n",
    "    \"\"\"\n",
    "    Approximates the AUC by the method described in Hand and Till 2001,\n",
    "    equation 3.\n",
    "    \n",
    "    NB: The class labels should be in the set [0,n-1] where n = # of classes.\n",
    "    The class probability should be at the index of its label in the predicted\n",
    "    probability list.\n",
    "    \n",
    "    Args:\n",
    "        y_true: actual labels of test data \n",
    "        y_pred_prob: predicted class probability\n",
    "        zero_label: label for positive class\n",
    "        one_label: label for negative class\n",
    "    Returns:\n",
    "        The A-value as a floating point.\n",
    "    \"\"\"\n",
    "    \n",
    "    idx = np.isin(y_true, [zero_label, one_label])\n",
    "    labels = y_true[idx]\n",
    "    prob = y_pred_prob[idx, zero_label]\n",
    "    sorted_ranks = labels[np.argsort(prob)]\n",
    "    \n",
    "    n0, n1, sum_ranks = 0, 0, 0\n",
    "    n0 = np.count_nonzero(sorted_ranks==zero_label)\n",
    "    n1 = np.count_nonzero(sorted_ranks==one_label)\n",
    "    sum_ranks = np.sum(np.where(sorted_ranks==zero_label)) + n0\n",
    "    \n",
    "    return (sum_ranks - (n0*(n0+1)/2.0)) / float(n0 * n1)  # Eqn 3\n",
    "\n",
    "class mAUC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(mAUC, self).__init__()\n",
    "#         self.data = data\n",
    "#         self.num_classes = num_classes\n",
    "    \n",
    "    def forward(self, y_true, y_pred_prob, num_classes):\n",
    "        import itertools\n",
    "        \"\"\"\n",
    "        Calculates the MAUC over a set of multi-class probabilities and\n",
    "        their labels. This is equation 7 in Hand and Till's 2001 paper.\n",
    "        NB: The class labels should be in the set [0,n-1] where n = # of classes.\n",
    "        The class probability should be at the index of its label in the\n",
    "        probability list.\n",
    "        I.e. With 3 classes the labels should be 0, 1, 2. The class probability\n",
    "        for class '1' will be found in index 1 in the class probability list\n",
    "        wrapped inside the zipped list with the labels.\n",
    "        Args:\n",
    "            data (list): A zipped list (NOT A GENERATOR) of the labels and the\n",
    "                class probabilities in the form (m = # data instances):\n",
    "                 [(label1, [p(x1c1), p(x1c2), ... p(x1cn)]),\n",
    "                  (label2, [p(x2c1), p(x2c2), ... p(x2cn)])\n",
    "                                 ...\n",
    "                  (labelm, [p(xmc1), p(xmc2), ... (pxmcn)])\n",
    "                 ]\n",
    "            num_classes (int): The number of classes in the dataset.\n",
    "        Returns:\n",
    "            The MAUC as a floating point value.\n",
    "        \"\"\"\n",
    "#         def MAUC(y_true, y_pred_prob, num_classes):\n",
    "        \"\"\"\n",
    "        Calculates the MAUC over a set of multi-class probabilities and\n",
    "        their labels. This is equation 7 in Hand and Till's 2001 paper.\n",
    "\n",
    "        NB: The class labels should be in the set [0,n-1] where n = # of classes.\n",
    "        The class probability should be at the index of its label in the\n",
    "        probability list.\n",
    "\n",
    "        Args:\n",
    "            y_true: actual labels of test data \n",
    "            y_pred_prob: predicted class probability\n",
    "            zero_label: label for positive class\n",
    "            one_label: label for negative class\n",
    "            num_classes (int): The number of classes in the dataset.\n",
    "\n",
    "        Returns:\n",
    "            The MAUC as a floating point value.\n",
    "        \"\"\"\n",
    "        # Find all pairwise comparisons of labels\n",
    "        class_pairs = [x for x in itertools.combinations(range(num_classes), 2)]\n",
    "\n",
    "        # Have to take average of A value with both classes acting as label 0 as this\n",
    "        # gives different outputs for more than 2 classes\n",
    "        sum_avals = 0\n",
    "        for pairing in class_pairs:\n",
    "            sum_avals += (a_value(y_true, y_pred_prob, zero_label=pairing[0], one_label=pairing[1]) +\n",
    "                          a_value(y_true, y_pred_prob, zero_label=pairing[1], one_label=pairing[0])) / 2.0\n",
    "        sum_avals = np.array([sum_avals])\n",
    "        sum_avals = torch.from_numpy(sum_avals)\n",
    "        return sum_avals * (2 / float(num_classes * (num_classes-1)))  # Eqn 7\n",
    "\n",
    "#CITE THE PAPER AND GITHUB https://github.com/pritomsaha/Multiclass_AUC/blob/master/multiclass_auc.ipynb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "9b07e9d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# num_classes = 3\n",
    "# y_true = np.array([0,1,1,0,2,2])\n",
    "# y_pred_prob = np.array([[0.5, 0.1, 0.4], [0.5, 0.3, 0.2], [0.1, 0.8, 0.1], [0, 0.4, 0.6], [0.3, 0.2, 0.5], [0.5, 0.1, 0.4]])\n",
    "# criterion = mAUC()\n",
    "# mauc = criterion(y_true, y_pred_prob, num_classes)\n",
    "# print(mauc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "da9a37c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BD_classify(nn.Module):\n",
    "    def __init__(self, in_layer, out_layer):\n",
    "        super(BD_classify, self).__init__()\n",
    "        self.in_layer = in_layer\n",
    "        self.out_layer = out_layer\n",
    "        self.avg = avg_pool()\n",
    "        self.layer1 = fc_layer(562500, out_layer)\n",
    "        self.softmax = softmax_layer()\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x0 = self.avg(x)\n",
    "        x0 = torch.flatten(x0, start_dim = 1, end_dim = -1)\n",
    "        x1 = self.layer1(x0)\n",
    "        x2 = self.softmax(x1)\n",
    "        return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "3a958352",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch_classify(net, data_loader, optimizer, criterion, epoch):\n",
    "    net.train()\n",
    "    loss_stat = []\n",
    "    for i, img_label in enumerate(data_loader):\n",
    "        img = img_label.get('image')\n",
    "        label = img_label.get('label')\n",
    "        img = img.to(device=device)\n",
    "#         label = torch.as_tensor(label)\n",
    "#         label_amount = len(label)\n",
    "#         label.resize_(label_amount)\n",
    "#         print(label)\n",
    "#         print(label.shape)\n",
    "        pred = net(img)\n",
    "#         print(pred.shape)\n",
    "        pred = pred.detach().numpy()\n",
    "#         print(pred)\n",
    "#         print(label)\n",
    "        loss = criterion(label, pred, 3)\n",
    "        loss = Variable(loss, requires_grad = True)\n",
    "#         print(loss)\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "#         print(loss.item())\n",
    "        loss_stat += [loss.item()]\n",
    "    \n",
    "#     print (\"Epoch {}: [{}/{}] Loss: {:.3f}\".format(epoch, len(data_loader), len(data_loader), np.mean(loss_stat))) \n",
    "    \n",
    "    return np.mean(loss_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "3605ac43",
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid_epoch_classify(net, data_loader, criterion, epoch):\n",
    "    net.eval()\n",
    "\n",
    "    val_loss_stat = []\n",
    "    for i, img_label in enumerate(data_loader):\n",
    "        img = img_label.get('image')\n",
    "        label = img_label.get('label')\n",
    "        img = img.to(device=device, dtype=torch.float32)\n",
    "#         label = torch.as_tensor(label)\n",
    "#         label_amount = len(label)\n",
    "#         label.resize_(label_amount, 1)\n",
    "        with torch.no_grad():\n",
    "            pred = net(img)\n",
    "            pred = pred.detach().numpy()\n",
    "            val_loss = criterion(label, pred, 3)\n",
    "      \n",
    "        val_loss_stat += [val_loss.item()]\n",
    "        \n",
    "#     print (\"Val Loss: {:.3f} \".format(np.mean(val_loss_stat)))\n",
    "    \n",
    "    return np.mean(val_loss_stat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "98f843e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "classification_data = ADNI_Dataset_classification(r\"C:/Users/pbhav/Desktop/NYU/ivp/project/ADNI/\", \"C:/Users/pbhav/Downloads/ADNI1_Annual_2_Yr_3T_4_23_2022.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "93b24344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "BD_classify(\n",
      "  (avg): avg_pool(\n",
      "    (avgp): AvgPool3d(kernel_size=2, stride=2, padding=0)\n",
      "  )\n",
      "  (layer1): fc_layer(\n",
      "    (fc): Linear(in_features=562500, out_features=3, bias=True)\n",
      "  )\n",
      "  (softmax): softmax_layer(\n",
      "    (softmax): Softmax(dim=1)\n",
      "  )\n",
      ")\n",
      "Number of parameters in network:  1687503\n"
     ]
    }
   ],
   "source": [
    "in_size = 200 #size after the transformer\n",
    "net1 = BD_classify(in_size, 3)\n",
    "net1.to(device)  # run net.to(device) if using GPU\n",
    "print(net1)\n",
    "\n",
    "n_params1 = sum(p.numel() for p in net1.parameters() if p.requires_grad)\n",
    "print('Number of parameters in network: ', n_params1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ef0a16fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#kfold validation for k = 5\n",
    "k=5\n",
    "splits=KFold(n_splits=k,shuffle=True,random_state=42)\n",
    "\n",
    "criterion = mAUC()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e84240f4",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1\n"
     ]
    }
   ],
   "source": [
    "foldperf1={}\n",
    "for fold, (train_idx, val_idx) in enumerate(splits.split(np.arange(len(classification_data)))):\n",
    "    train_idx = np.delete(train_idx, 0)\n",
    "    val_idx = np.delete(val_idx, 0)\n",
    "    print('Fold {}'.format(fold + 1))\n",
    "    \n",
    "    train_sampler = SubsetRandomSampler(train_idx)\n",
    "    test_sampler = SubsetRandomSampler(val_idx)\n",
    "    train_loader = torch.utils.data.DataLoader(classification_data, batch_size=BATCH_SIZE, sampler=train_sampler)\n",
    "    test_loader = torch.utils.data.DataLoader(classification_data, batch_size=BATCH_SIZE, sampler=test_sampler)\n",
    "\n",
    "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "    net1.to(device)\n",
    "    optimizer = optim.Adam(net1.parameters(), lr=LR)\n",
    "\n",
    "    history = {'train_loss': [], 'test_loss': []}\n",
    "\n",
    "    for epoch in range(NUM_EPOCH):\n",
    "        train_loss =train_epoch_classify(net1, train_loader, optimizer, criterion, epoch)\n",
    "        test_loss =valid_epoch_classify(net1, test_loader, criterion, epoch)\n",
    "#         train_loss = train_loss / len(train_loader.sampler)\n",
    "#         test_loss = test_loss / len(test_loader.sampler)\n",
    "\n",
    "        print(\"Epoch:{}/{} AVG Training Loss:{:.3f} AVG Test Loss:{:.3f}\".format(epoch + 1, NUM_EPOCH, train_loss, test_loss))\n",
    "        history['train_loss'].append(train_loss)\n",
    "        history['test_loss'].append(test_loss)\n",
    "\n",
    "#         Save the model after each epoch\n",
    "        if os.path.isdir(SAVE_PATH_BC):\n",
    "            torch.save(net1.state_dict(),SAVE_PATH_BC + '\\epoch{}.pth'.format(epoch + 1))\n",
    "        else:\n",
    "            os.makedirs(model_save_path, exist_ok=True)\n",
    "            torch.save(net1.state_dict(),SAVE_PATH_BC + '\\epoch{}.pth'.format(epoch + 1))\n",
    "        print('Checkpoint {} saved to {}'.format(epoch + 1, SAVE_PATH_BC + '\\epoch{}.pth'.format(epoch + 1)))   \n",
    "    foldperf1['fold{}'.format(fold+1)] = history  \n",
    "\n",
    "torch.save(net1,'k_cross1.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "438d71ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "testl_f1, tl_f1 = [], []\n",
    "\n",
    "for f in range(1,k+1):\n",
    "    tl_f1.append(np.mean(foldperf1['fold{}'.format(f)]['train_loss']))\n",
    "    testl_f1.append(np.mean(foldperf1['fold{}'.format(f)]['test_loss']))\n",
    "\n",
    "print('Performance of {} fold cross validation'.format(k))\n",
    "print(\"Average Training Loss: {:.3f} \\t Average Test Loss: {:.3f}\".format(np.mean(tl_f1), np.mean(testl_f1)))     \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4af40485",
   "metadata": {},
   "source": [
    "#  Segmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f91acc7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
